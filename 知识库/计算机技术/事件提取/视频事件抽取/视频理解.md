# 视频理解
## 1.深度学习之后
CNN+RNN： 这种类型的网络以LRCN[9]为代表，利用CNN提取单帧图片的空间特征，然后利用RNN系列的网络对提取好的单帧图片特征进行时序建模，最后得到视频片段的预测结果。
优点：可以直接自然地利用在大规模图像数据集比如ImageNet上的预训练结果。
缺点：后端的RNN网络是对高层次的语义特征进行建模，对于低层次的运动motion特征则爱莫能助，因为低层次的motion信息很多时候都取决于了前端的CNN的能力，而前端的CNN在此时并没有motion建模的能力。
总结： 因此，LRCN系列的网络对于单帧appearance差别明显的数据集，表现可能会更为理想。模型参数量在三种基本模型中最小。

3D-ConvNet ： 3D卷积网络以C3D[12]为典型代表，将2D卷积核在时间方向延伸了一个维度，自然地形成了3D卷积核，以期望用3D卷积核的层叠学习到视频的时空语义特征。
优点：是2D卷积的自然延伸，一站式地学习motion和appearance信息，能理论上真正做到时空语义的提取。
缺点：参数量是3次方级别的，参数量过大，容易导致过拟合。不能直接地利用在图像数据集上的预训练模型进行初始化模型参数。
总结 ： 3D卷积网络在高维医学图像和视频分析中都有广阔的应用，其存在很多尝试分解3D卷积成2D+1D卷积的操作，而且都有不错的效果。模型参数量在三种基本模型中最大。

Two-Stream： 双流网络[]显式地分割了motion流和appearance流两种信息，（大部分）利用人工设计的光流特征进行视频的motion信息建模，用RGB片段的单帧信息作为appearance信息，利用预训练的CNN进行特征提取后，融合不同流的预测结果得到最终视频片段的预测。
优点：可以直接自然地利用预训练的大多数CNN网络，如VGG，ResNet等。效果良好，现在很多工作都是基于双流网络进行改造而成。直接用光流信息去建模motion信息，使得在较小样本的数据集中也能有不错效果。
缺点：大部分工作的光流信息都是需要预训练的，这样无法提供一个端到端的预训练场景，同时，光流计算耗费较多的计算资源。
总结： 双流网络是目前动作识别领域较为常用的基本模型，其效果良好，模型参数量在三种基本模型之间。

![三种基本的对视频动作进行分析的模型框架。](https://picx.zhimg.com/100/v2-b8f48bbf04dbbb932fb6305f8179d637_r.jpeg)
Fig 4.1 三种基本的对视频动作进行分析的模型框架。

## 2. 双流融合网络（Two Stream Fused Network）

作者在conv5层后进行双流信息的3D conv fusion融合，同时，作者并没有截断时间流信息（这里的时间流信息是多张RGB帧层叠而成，见Fig 4.7的右半部分），而是用刚才提到的时序信息融合，用3D Conv+3D Pooling的方式融合了时序信息流，于是我们有两个分支：一个是时间-空间双流融合信息，一个是时序特征流。如Fig 4.8的spatia-temporal loss和temporal loss所示。

![输入图片描述](https://pica.zhimg.com/100/v2-8a783dba5a17dc02cf3bd97181869dc3_r.jpeg?source=2c26e567&rawwidth=313&rawheight=476&customSceneCode=image_viewer)
Fig 4.7 双流融合网络的主干框架。

![输入图片描述](https://picx.zhimg.com/100/v2-2dbcf9dd3ca1896fb077d1da7879daea_r.jpeg?source=2c26e567&rawwidth=864&rawheight=399&customSceneCode=image_viewer)
Fig 4.8 双流融合网络的网络框图，主要有时空损失和时序损失组成，其前端和传统的双流网络没有太大区别，主要是在时序融合上采用了3D conv+3D pooling的方式。

整个网络的实验结果如下图所示：
![输入图片描述](https://pic1.zhimg.com/100/v2-f62b0f210f68338d9be63b5a50a9956b_r.jpeg?source=2c26e567&rawwidth=376&rawheight=241&customSceneCode=image_viewer)

双流融合网络在用少于C3D的参数量的同时，提高了模型性能，是双流信息融合网络系列的开山鼻祖。我们之后的很多网络，包括I3D等，都是由它启发而来。

## 3. 将2D卷积网络预训练模型扩展到3D卷积网络上——I3D模型
![输入图片描述](https://pic1.zhimg.com/100/v2-5220e612d426b726e1ac264f2e26599b_r.jpeg?source=2c26e567&rawwidth=1007&rawheight=317&customSceneCode=image_viewer)
Fig 4.9 五种动作识别的网络简图，前四种我们已经介绍过了。其中的K代表的是整个视频的长度，N表示的是某个帧周围的邻居的长度，比如某个时间帧t，如果N=10，那么就会在[t-5,t+5]的范围内对视频采样。
